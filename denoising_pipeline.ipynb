{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    " \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "from torcheval.metrics.functional import binary_f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import monai\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "import torchmetrics\n",
    "import piq\n",
    "from loss_functions import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined parameters\n",
    "\n",
    "train_batch_size = 224 # Batch size used for train and val, bigger since we are training on patches\n",
    "test_batch_size = 64 # Batch size used for test, may need to be smaller since we are testing on full images\n",
    "num_epochs = 150 # TUNE, want it to be big enough that model converges \n",
    "eval_freq = 1 # How often to evaluate model on val set, set to 1 to evaluate every epoch or ~5 if validation is taking too long\n",
    "learning_rate = 0.001\n",
    "loss_name = \"edge_loss\"\n",
    "net_name = \"unet_stride_1\"\n",
    "save_path = 'experiment_models' # Parent logging directory\n",
    "run_name = f'{net_name}_loss_{loss_name}_lr_{learning_rate}' # Unique identifier for this experiment\n",
    "\n",
    "data_file_name = 'data_file_name.h5' # (Relative) file path to read data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically defined parameters\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running model on device: {device}')\n",
    "\n",
    "\n",
    "# Set up save paths\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "full_save_path = os.path.join(save_path, run_name)\n",
    "txt_log_path = os.path.join(full_save_path, 'training_log.txt')\n",
    "model_save_path = os.path.join(full_save_path, 'models')\n",
    "figure_save_path = os.path.join(full_save_path, 'figures')\n",
    "\n",
    "if os.path.exists(full_save_path):\n",
    "    warnings.warn(f'Save path {full_save_path} already exists')\n",
    "os.makedirs(full_save_path, exist_ok=True)\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "os.makedirs(figure_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloader\n",
    "\n",
    "class h5DenoisingDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Torch dataset class for reading in clean/noisy data from h5 files. \n",
    "\n",
    "    @args:\n",
    "        h5_filepath (str): path to the h5 file containing the data\n",
    "        split (str, {'train','val','test'}): indicates which data split this is\n",
    "        patch_size (int): size of the patches to extract from the images, used only for training and validation\n",
    "    @rets:\n",
    "        clean_image (torch.tensor): clean image to use as ground truth, torch tensor of shape (C, H, W)\n",
    "        noisy_image (torch.tensor): noisy image to use as input, torch tensor of shape (C, H, W)\n",
    "        noise_sigma (float): noise level of the noisy image\n",
    "        sample_id (str): ID identifying this sample\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, h5_filepath, split, patch_size=64):\n",
    "\n",
    "        # Save variables\n",
    "        self.h5_filepath = h5_filepath\n",
    "        self.split = split\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # Get all keys from h5 file\n",
    "        with h5py.File(h5_filepath, 'r') as f:\n",
    "            self.keys = list(f.keys())\n",
    "            \n",
    "        # Split the keys into train, val, and test by case number\n",
    "        all_cases = list(set([int(key.split('_')[1]) for key in self.keys]))\n",
    "        random.seed(42)\n",
    "        random.shuffle(all_cases)\n",
    "        n = len(all_cases)\n",
    "        if split == 'train': self.cases = all_cases[:int(0.6*n)]\n",
    "        elif split == 'val': self.cases = all_cases[int(0.6*n):int(0.8*n)]\n",
    "        elif split == 'test': self.cases = all_cases[int(0.8*n):]\n",
    "        else: raise ValueError('Invalid split argument. Must be one of {train, val, test}')\n",
    "\n",
    "        # Get all keys for this split\n",
    "        self.keys = [key for key in self.keys if int(key.split('_')[1]) in self.cases]\n",
    "\n",
    "        # Define transforms\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomCrop(self.patch_size), # Random crop train set to increase training data variance\n",
    "        ])\n",
    "        self.val_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.CenterCrop(self.patch_size), # Center crop val set to maintain consistent val set that runs quickly\n",
    "        ])\n",
    "        self.test_transform = transforms.Compose([\n",
    "            transforms.ToTensor() # No crop on test set\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Load image at this index\n",
    "        with h5py.File(self.h5_filepath, 'r') as h5file:\n",
    "            clean_image = h5file[self.keys[index]]['clean'][()]\n",
    "            noisy_image = h5file[self.keys[index]]['noisy'][()]\n",
    "            noise_sigma = h5file[self.keys[index]]['noise_sigma'][()]\n",
    "\n",
    "        # Transform input\n",
    "        seed = np.random.randint(214)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if self.split == 'train': clean_image = self.train_transform(clean_image)\n",
    "        elif self.split == 'val': clean_image = self.val_transform(clean_image)\n",
    "        else: clean_image = self.test_transform(clean_image)\n",
    "        \n",
    "        # Transform output\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if self.split == 'train': noisy_image = self.train_transform(noisy_image)\n",
    "        elif self.split == 'val': noisy_image = self.val_transform(noisy_image)\n",
    "        else: noisy_image = self.test_transform(noisy_image)\n",
    "\n",
    "        return clean_image, noisy_image, noise_sigma, self.keys[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define util functions\n",
    "\n",
    "def print_and_save(print_str, file_path):\n",
    "    \"\"\"\n",
    "    Prints string and saves string to file_path\n",
    "    \"\"\"\n",
    "    print(print_str)\n",
    "    with open(file_path, 'a') as f:\n",
    "        f.write(print_str + '\\n')\n",
    "\n",
    "def compute_denoising_metrics(predicted, true):\n",
    "    \"\"\"\n",
    "    Computes common denoising metrics\n",
    "    Takes batches of tensors as input (B, C, H, W), returns average metrics as floats\n",
    "    \"\"\"\n",
    "    ssim = torchmetrics.functional.image.structural_similarity_index_measure(predicted, true, data_range=220)\n",
    "    psnr = torchmetrics.functional.image.peak_signal_noise_ratio(predicted, true, data_range=220) \n",
    "    mse = torchmetrics.functional.mean_squared_error(predicted, true)\n",
    "    # TODO: add more denoising metrics here, particulalry those that capture high frequency information. Potential ref: https://lightning.ai/docs/torchmetrics/stable/image/\n",
    "    return ssim.item(), psnr.item(), mse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define datasets \n",
    "\n",
    "trainset = h5DenoisingDataset(h5_filepath=data_file_name, split='train')\n",
    "valset = h5DenoisingDataset(h5_filepath=data_file_name, split='val')\n",
    "testset = h5DenoisingDataset(h5_filepath=data_file_name, split='test')\n",
    "\n",
    "print_and_save(f\"Length of trainset: {len(trainset)}\", txt_log_path)\n",
    "print_and_save(f\"Length of valset: {len(valset)}\", txt_log_path)\n",
    "print_and_save(f\"Length of testset: {len(testset)}\", txt_log_path)\n",
    "\n",
    "\n",
    "# Define dataloaders\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True, num_workers=4)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=train_batch_size, shuffle=False, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few samples from each split as a gut check\n",
    "\n",
    "num_plots = 2\n",
    "do_check = True\n",
    "\n",
    "if do_check:\n",
    "    for split, loader in [(\"Train\",trainloader), (\"Val\",valloader), (\"Test\",testloader)]:\n",
    "\n",
    "        # Get this split's data loader\n",
    "        print('\\nSplit:',split,'\\n')\n",
    "        dataiter = iter(loader)\n",
    "\n",
    "        for plot_count in range(num_plots):\n",
    "\n",
    "            # Sample from loader\n",
    "            clean_image, noisy_image, noise_sigma, key = next(dataiter)\n",
    "            \n",
    "            # Print info about sample and plot it\n",
    "            batch_ind = 0\n",
    "\n",
    "            print(f'Size of clean images: {clean_image.shape}, min of clean image: {torch.min(clean_image[batch_ind])}, max of clean image: {torch.max(clean_image[batch_ind])}')\n",
    "            print(f'Size of noisy images: {noisy_image.shape}, min of noisy image: {torch.min(noisy_image[batch_ind])}, max of noisy image: {torch.max(noisy_image[batch_ind])}')\n",
    "            print(f'Noise sigma: {noise_sigma[batch_ind]}')\n",
    "            \n",
    "            fig, ax = plt.subplots(1,2,figsize=(5,2))\n",
    "            ax[0].imshow(clean_image[batch_ind][0].numpy(),cmap='gray')\n",
    "            ax[0].axis('off')\n",
    "            ax[0].set_title('Clean')\n",
    "            ax[1].imshow(noisy_image[batch_ind][0].numpy(),cmap='gray')\n",
    "            ax[1].axis('off')\n",
    "            ax[1].set_title('Noisy')\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "# TODO: decide on architecture to run experiments with\n",
    "#net = monai.networks.nets.HighResNet(spatial_dims=2, in_channels=1, out_channels=1)\n",
    "\n",
    "channels = [32, 64, 128, 256, 512]  # Example channels configuration\n",
    "strides = [1, 1, 1, 1]  # Example strides configuration (len(channels) - 1)\n",
    "net = monai.networks.nets.UNet(spatial_dims=2, in_channels=1, out_channels=1, channels=channels, strides=strides)\n",
    "#net = monai.networks.nets.HighResNet(spatial_dims=2, in_channels=1, out_channels=1)\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "# TODO: try out a few learning rates after finding a good architecture\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss\n",
    "\n",
    "#criterion = torch.nn.MSELoss()\n",
    "#criterion = RiemannianLoss(gamma=0.75)\n",
    "#criterion = torch.nn.L1Loss()\n",
    "#criterion = torch.nn.HuberLoss(reduction='mean', delta=0.75)\n",
    "criterion = EdgeLoss(alpha=0.7)\n",
    "#criterion = Charbonnier_Loss()\n",
    "#criterion = FeaturePreservingLoss()\n",
    "#criterion = GeneralizedLoss(alpha=1.25, c=2)\n",
    "#criterion = DiceLoss()\n",
    "#criterion = PSNR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "print_and_save(\"\\nStarting training:\", txt_log_path)\n",
    "\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_count = 0\n",
    "    print_and_save('\\nEpoch {}'.format(epoch), txt_log_path)\n",
    "\n",
    "    # Put model in train mode\n",
    "    net.train()\n",
    "    \n",
    "    for i, (clean_images, noisy_images, noise_sigmas, keys) in enumerate(tqdm(trainloader)):   \n",
    "\n",
    "        # Put the tensors onto the device\n",
    "        clean_images = clean_images.to(device)\n",
    "        noisy_images = noisy_images.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        predicted_images = net(noisy_images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(predicted_images, clean_images)\n",
    "\n",
    "        # Backward pass and optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        running_loss += loss.item()\n",
    "        running_count += 1\n",
    "\n",
    "    # Save train statistics \n",
    "    print_and_save('\\tTrain loss: %.3f' %(running_loss / running_count), txt_log_path)\n",
    "\n",
    "    # Validation loop\n",
    "    if epoch % eval_freq == 0:\n",
    "\n",
    "        # Put model in eval mode\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            save_plot = True\n",
    "            num_plots = 5\n",
    "            running_loss = 0\n",
    "            running_count = 0\n",
    "            for i, (clean_images, noisy_images, noise_sigmas, keys) in enumerate(tqdm(valloader)):   \n",
    "\n",
    "                # Send images to device and predict clean images\n",
    "                clean_images = clean_images.to(device)\n",
    "                noisy_images = noisy_images.to(device)\n",
    "                predicted_images = net(noisy_images)\n",
    "\n",
    "                # Save a num_plots number of plots if save_plot is True\n",
    "                if save_plot and i<num_plots:\n",
    "                    clean_image = clean_images[0][0].cpu().numpy()\n",
    "                    noisy_image = noisy_images[0][0].cpu().numpy()\n",
    "                    predited_image = predicted_images[0][0].detach().cpu().numpy()\n",
    "                    key = keys[0]\n",
    "\n",
    "                    # Set up figure save paths\n",
    "                    full_figure_save_path = os.path.join(figure_save_path, 'val')\n",
    "                    os.makedirs(full_figure_save_path, exist_ok=True)\n",
    "                    full_figure_save_path = os.path.join(figure_save_path, 'val', key)\n",
    "                    os.makedirs(full_figure_save_path, exist_ok=True)\n",
    "\n",
    "                    # Plot and save\n",
    "                    fig, ax = plt.subplots(1,3)\n",
    "                    ax[0].imshow(noisy_image,cmap='gray')\n",
    "                    ax[0].axis('off')\n",
    "                    ax[0].set_title('Noisy')\n",
    "                    ax[1].imshow(predited_image,cmap='gray')\n",
    "                    ax[1].axis('off')\n",
    "                    ax[1].set_title('Predict')\n",
    "                    ax[2].imshow(clean_image,cmap='gray')\n",
    "                    ax[2].axis('off')\n",
    "                    ax[2].set_title('GT')\n",
    "                    plt.savefig(os.path.join(full_figure_save_path, f'epoch_{epoch}.png'))\n",
    "                    plt.close()\n",
    "\n",
    "                # Track validation loss\n",
    "                loss = criterion(predicted_images, clean_images)\n",
    "                running_loss += loss.item()\n",
    "                running_count += 1\n",
    "      \n",
    "                # Clean up memory\n",
    "                del clean_images, noisy_images, noise_sigmas, keys, predicted_images\n",
    "            \n",
    "            print_and_save('\\tValidation loss: %.3f' %(running_loss / running_count), txt_log_path)\n",
    "\n",
    "            # Save model if this is the best model so far, according to the loss function\n",
    "            if running_loss / running_count < best_val_loss:\n",
    "                best_val_loss = running_loss / running_count\n",
    "                torch.save(net.state_dict(), os.path.join(model_save_path, f'best_model.pth'))\n",
    "                print_and_save(f'\\tCheckpointing epoch {epoch} model at best_model.pth', txt_log_path)\n",
    "\n",
    "# Save final model \n",
    "print_and_save(f'\\nFinished training, saving final model at final_model.pth', txt_log_path)\n",
    "torch.save(net.state_dict(), os.path.join(model_save_path, f'final_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load chosen model\n",
    "chosen_load_path = os.path.join(model_save_path, 'best_model.pth') # Can change this to load a different model\n",
    "print_and_save(f'\\nLoading model from {chosen_load_path} for final evaluations', txt_log_path)\n",
    "net.load_state_dict(torch.load(chosen_load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation loop and save metrics for chosen model\n",
    " \n",
    "print_and_save(f'\\nRunning validation loop...', txt_log_path)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    all_ssim = []\n",
    "    all_psnr = []\n",
    "    all_mse = []\n",
    "    for i, (clean_images, noisy_images, noise_sigmas, keys) in enumerate(tqdm(valloader)):   \n",
    "\n",
    "        clean_images = clean_images.to(device)\n",
    "        noisy_images = noisy_images.to(device)\n",
    "        predicted_images = net(noisy_images)\n",
    "\n",
    "        batch_ssim, batch_psnr, batch_mse = compute_denoising_metrics(predicted_images, clean_images)\n",
    "\n",
    "        all_ssim += [batch_ssim]*clean_images.shape[0]\n",
    "        all_psnr += [batch_psnr]*clean_images.shape[0]\n",
    "        all_mse += [batch_mse]*clean_images.shape[0]\n",
    "    \n",
    "print_and_save(f'Validation SSIM: {np.mean(all_ssim)}', txt_log_path)\n",
    "print_and_save(f'Validation PSNR: {np.mean(all_psnr)}', txt_log_path)\n",
    "print_and_save(f'Validation MSE: {np.mean(all_mse)}', txt_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test loop and save metrics for chosen model\n",
    "\n",
    "print_and_save(f'\\nRunning test loop...', txt_log_path)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    all_ssim = []\n",
    "    all_psnr = []\n",
    "    all_mse = []\n",
    "    for i, (clean_images, noisy_images, noise_sigmas, keys) in enumerate(tqdm(testloader)):   \n",
    "\n",
    "        clean_images = clean_images.to(device)\n",
    "        noisy_images = noisy_images.to(device)\n",
    "        predicted_images = net(noisy_images)\n",
    "\n",
    "        batch_ssim, batch_psnr, batch_mse = compute_denoising_metrics(predicted_images, clean_images)\n",
    "\n",
    "        all_ssim += [batch_ssim]*clean_images.shape[0]\n",
    "        all_psnr += [batch_psnr]*clean_images.shape[0]\n",
    "        all_mse += [batch_mse]*clean_images.shape[0]\n",
    "    \n",
    "print_and_save(f'Test SSIM: {np.mean(all_ssim)}', txt_log_path)\n",
    "print_and_save(f'Test PSNR: {np.mean(all_psnr)}', txt_log_path)\n",
    "print_and_save(f'Test MSE: {np.mean(all_mse)}', txt_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and save a few samples from the test set\n",
    "num_plots = 5\n",
    "for test_ind in random.sample(range(len(testset)), num_plots):\n",
    "    \n",
    "    clean_image, noisy_image, noise_sigma, key = testset[test_ind]\n",
    "    clean_image = clean_image.unsqueeze(0).to(device)\n",
    "    noisy_image = noisy_image.unsqueeze(0).to(device)\n",
    "    predicted_image = net(noisy_image)\n",
    "    clean_image = clean_image[0][0].cpu().numpy()\n",
    "    noisy_image = noisy_image[0][0].cpu().numpy()\n",
    "    predicted_image = predicted_image[0][0].detach().cpu().numpy()\n",
    "\n",
    "    full_figure_save_path = os.path.join(figure_save_path, 'test')\n",
    "    os.makedirs(full_figure_save_path, exist_ok=True)\n",
    "    full_figure_save_path = os.path.join(figure_save_path, 'test', key)\n",
    "    os.makedirs(full_figure_save_path, exist_ok=True)\n",
    "\n",
    "    # Plot full image\n",
    "    fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "    ax[0].imshow(noisy_image,cmap='gray')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Noisy')\n",
    "    ax[1].imshow(predicted_image,cmap='gray')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Predict')\n",
    "    ax[2].imshow(clean_image,cmap='gray')\n",
    "    ax[2].axis('off')\n",
    "    ax[2].set_title('GT')\n",
    "    plt.savefig(os.path.join(full_figure_save_path, f'full_image.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot zoomed in center patch\n",
    "    patch_start_ind_x = 64\n",
    "    patch_end_ind_x = 128\n",
    "    patch_start_ind_y = 85\n",
    "    patch_end_ind_y = 170\n",
    "\n",
    "    fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "    ax[0].imshow(noisy_image[patch_start_ind_x:patch_end_ind_x,patch_start_ind_y:patch_end_ind_y],cmap='gray')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Noisy')\n",
    "    ax[1].imshow(predicted_image[patch_start_ind_x:patch_end_ind_x,patch_start_ind_y:patch_end_ind_y],cmap='gray')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Predict')\n",
    "    ax[2].imshow(clean_image[patch_start_ind_x:patch_end_ind_x,patch_start_ind_y:patch_end_ind_y],cmap='gray')\n",
    "    ax[2].axis('off')\n",
    "    ax[2].set_title('GT')\n",
    "    plt.savefig(os.path.join(full_figure_save_path, f'center_patch.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = data_file_name\n",
    "\n",
    "with h5py.File(filepath, 'r') as f:\n",
    "    keys = list(f.keys())\n",
    "    print(len(keys))\n",
    "    for key in list(keys):\n",
    "        print(key)\n",
    "        clean_image = f[key]['clean'][()]\n",
    "        noisy_image = f[key]['noisy'][()]\n",
    "        noise_sigma = f[key]['noise_sigma'][()]\n",
    "\n",
    "        print(clean_image.shape)\n",
    "        print(noisy_image.shape)\n",
    "        print(noise_sigma)\n",
    "\n",
    "        fig, ax = plt.subplots(1,2)\n",
    "        ax[0].imshow(clean_image, cmap='gray')\n",
    "        ax[1].imshow(noisy_image, cmap='gray')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
